from sentence_transformers import SentenceTransformer
import faiss
import json
import numpy as np

# === Load your structured slide data ===
with open("report_slides.json", "r", encoding="utf-8") as f:
    report = json.load(f)

# === Extract chunks for embedding ===
chunks = []
metas = []
for slide in report["slides"]:
    for element in slide["elements"]:
        content = " ".join(element["content"]).strip()
        if content:
            chunks.append(content)
            metas.append({
                "section": slide["title"],
                "type": element["type"],
                "title": element["title"]
            })

# === Generate embeddings ===
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(chunks, convert_to_numpy=True)

# === Create FAISS vector index ===
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

# === Wrap for querying ===
def retrieve_top_k(query, top_k=3):
    query_vec = model.encode([query], convert_to_numpy=True)
    distances, indices = index.search(query_vec, top_k)
    results = []
    for i in indices[0]:
        results.append({
            "text": chunks[i],
            "meta": metas[i]
        })
    return results

# === Example usage ===
if __name__ == "__main__":
    query = "What is the FY24 profit?"
    results = retrieve_top_k(query)
    for res in results:
        print(f"\n🔹 Section: {res['meta']['section']}")
        print(f"📌 Type: {res['meta']['type']}")
        print(f"📝 Text: {res['text'][:300]}...")
